{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nupur412/hiwitask/blob/main/Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w24dpS2BIwiE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import EMNIST\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "_1DZLZYqI5HO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code defines a Resnet-9 Encoder which is without the classification layer"
      ],
      "metadata": {
        "id": "ZJPXWnEDpI3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False, pool_no=2):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU()\n",
        "              ]\n",
        "    if pool: layers.append(nn.MaxPool2d(pool_no))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9Features(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=47):\n",
        "        super(ResNet9Features, self).__init__()\n",
        "\n",
        "        self.conv1 = conv_block(1, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True, pool_no=2)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "\n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 256, pool=True, pool_no=2)\n",
        "        self.res2 = nn.Sequential(conv_block(256, 256), conv_block(256, 256))\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.FlatFeats = nn.Flatten()\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.global_avg_pool(out)\n",
        "        out = self.FlatFeats(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "X3_IaSN6I89I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the EMNIST dataset\n",
        "emnist_train_dataset = datasets.EMNIST(root='./data', split='balanced', train=True, transform=transform, download=True)\n",
        "emnist_test_dataset = datasets.EMNIST(root='./data', split='balanced', train=False, transform=transform, download=True)\n",
        "\n",
        "# Split the dataset into classes\n",
        "classes = np.unique(emnist_train_dataset.targets.numpy())\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duHadcoOJRVz",
        "outputId": "e294d138-7b40-4625-f2e5-ad0fdf3d3924"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(emnist_train_dataset))\n",
        "val_size = len(emnist_train_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(emnist_train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(emnist_test_dataset, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "oraFKXwPJpmi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code defines a SIMCLR class that uses Resnet9 as the base encoder"
      ],
      "metadata": {
        "id": "nRk8KfJCpi6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, base_encoder, projection_dim=128):\n",
        "        super(SimCLR, self).__init__()\n",
        "\n",
        "        # Base Encoder\n",
        "        self.base_encoder = base_encoder\n",
        "\n",
        "        # Projection Head\n",
        "        self.projection_head = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, projection_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # Encoding both augmented views\n",
        "        h1 = self.base_encoder(x1)\n",
        "        h2 = self.base_encoder(x2)\n",
        "\n",
        "        # Projection Head\n",
        "        z1 = self.projection_head(h1)\n",
        "        z2 = self.projection_head(h2)\n",
        "\n",
        "        return h1, h2, z1, z2\n",
        "\n",
        "    def loss_function(z1, z2, temperature=0.5):\n",
        "        # Normalizing the embeddings\n",
        "        z1 = F.normalize(z1, dim=-1, p=2)\n",
        "        z2 = F.normalize(z2, dim=-1, p=2)\n",
        "\n",
        "        # Computing cosine similarity\n",
        "        sim_scores = F.cosine_similarity(z1, z2, dim=-1) / temperature\n",
        "\n",
        "        # Creating labels for cross entropy (positive pairs have label 1, negative pairs have label 0)\n",
        "        labels = torch.ones_like(sim_scores)\n",
        "\n",
        "        # Loss calculation using cross entropy with logits\n",
        "        loss = F.cross_entropy(sim_scores.unsqueeze(1), labels.long())\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "dEKE6rdlJ3fM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model and data to the GPU\n",
        "base_encoder = ResNet9Features().to(device)\n",
        "simclr_model = SimCLR(base_encoder).to(device)"
      ],
      "metadata": {
        "id": "g9uaSwhjKYzD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InfoNCELoss(nn.Module):\n",
        "    def __init__(self, temperature=1.0):\n",
        "        super(InfoNCELoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, z1, z2):\n",
        "        # Normalize embeddings\n",
        "        z1 = F.normalize(z1, dim=1)\n",
        "        z2 = F.normalize(z2, dim=1)\n",
        "\n",
        "        # Cosine similarity\n",
        "        similarity_matrix = torch.matmul(z1, z2.t()) / self.temperature\n",
        "\n",
        "        # Create labels for positive pairs\n",
        "        labels = torch.arange(similarity_matrix.size(0)).to(z1.device)\n",
        "\n",
        "        # Calculate InfoNCE loss\n",
        "        loss = F.cross_entropy(similarity_matrix, labels)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "# Instantiate the InfoNCELoss function\n",
        "criterion = InfoNCELoss(temperature=0.5).to(device)"
      ],
      "metadata": {
        "id": "xMH6U5RgLvCk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below trains the SIMCLR model"
      ],
      "metadata": {
        "id": "fu5o9fugqEes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "# Set up the optimizer and learning rate scheduler\n",
        "optimizer = torch.optim.Adam(simclr_model.parameters(), lr=0.15)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0, last_epoch=-1)\n",
        "\n",
        "# Set the temperature for the contrastive loss\n",
        "temperature = 0.5\n",
        "\n",
        "encoder_representations = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    simclr_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}'):\n",
        "        # Extract the batch of images\n",
        "        x = batch[0].to(device)\n",
        "\n",
        "        # Data augmentation\n",
        "        augmentations = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(28),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "        ])\n",
        "\n",
        "        x1 = augmentations(x)\n",
        "\n",
        "        # Move data to device\n",
        "        x, x1 = x.to(device), x1.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        h1, h2, proj1, proj2 = simclr_model(x, x1)\n",
        "\n",
        "        # Save encoder representations for further use\n",
        "        encoder_representations.append(h1.detach().cpu().numpy())\n",
        "\n",
        "        # Compute SimCLR loss\n",
        "        loss = criterion(proj1, proj2)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Loss: {average_loss:.4f}')\n",
        "\n",
        "    # Adjust learning rate with scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "# Save encoder representations to a file\n",
        "torch.save({'encoder_representations': encoder_representations}, 'encoder_representations.pth')\n"
      ],
      "metadata": {
        "id": "dcxElqy5Q-vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuning for a downstream task"
      ],
      "metadata": {
        "id": "CPqFd0o2qMKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "\n",
        "simclr_model.load_state_dict(torch.load('simclr_model.pth'))\n",
        "\n",
        "# Adding a classification layer outside the SimCLR model\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_features, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in simclr_model.encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "classifier_learning_rate = 0.001\n",
        "classifier = Classifier(in_features=128, num_classes=47)\n",
        "classifier.to(device)"
      ],
      "metadata": {
        "id": "G-Nf7jFZpEf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=0.01)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "jb96pKMyspbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "for epoch in range (num_epochs):\n",
        "    classifier.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    classifier.eval()\n",
        "    with torch.no_grad():\n",
        "        total_val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = classifier(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        average_val_loss = total_val_loss / len(val_loader)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
        "          f'Training Loss: {average_loss:.4f}, '\n",
        "          f'Validation Loss: {average_val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Testing\n",
        "classifier.eval()\n",
        "with torch.no_grad():\n",
        "    total_test_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = classifier(inputs)\n",
        "        test_loss = criterion(outputs, labels)\n",
        "        total_test_loss += test_loss.item()\n",
        "\n",
        "        _, predicted_test = outputs.max(1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += predicted_test.eq(labels).sum().item()\n",
        "\n",
        "    average_test_loss = total_test_loss / len(test_loader)\n",
        "    test_accuracy = 100 * correct_test / total_test\n",
        "\n",
        "print(f'Testing Loss: {average_test_loss:.4f}, Testing Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "o8h7nRqDtB-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load representation vectors from the saved file\n",
        "representation_vectors = torch.load('encoder_representations.pth')"
      ],
      "metadata": {
        "id": "vH-E-VFZtXMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "representation_vectors_cpu = representation_vectors.cpu()\n",
        "\n",
        "# Convert the PyTorch tensor to a NumPy array\n",
        "representation_vectors_np = representation_vectors_cpu.numpy()"
      ],
      "metadata": {
        "id": "8XfpeW9_tcw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code defines a class LSH - Local Sensitive Hashing"
      ],
      "metadata": {
        "id": "bOiS5lMotsU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSH:\n",
        "    def __init__(self, num_buckets, projection_dim, seed=None):\n",
        "        np.random.seed(seed)\n",
        "        self.num_buckets = num_buckets\n",
        "        self.projection_dim = projection_dim\n",
        "        self.projections = np.random.randn(projection_dim, self.num_buckets)\n",
        "\n",
        "    def hash_vector(self, vector):\n",
        "        # Project the vector using random projections\n",
        "        projections_result = np.dot(self.projections, vector)\n",
        "\n",
        "        # Apply a sign function to obtain hash codes\n",
        "        hash_codes = np.sign(projections_result)\n",
        "\n",
        "        # Convert the hash codes to integers\n",
        "        hash_indices = int(\"\".join(map(str, (hash_codes > 0).astype(int))), 2)\n",
        "\n",
        "        return hash_indices\n",
        "\n",
        "    def hash_dataset(self, dataset):\n",
        "        # Hash each vector in the dataset\n",
        "        hashed_data = [self.hash_vector(vector) for vector in dataset]\n",
        "\n",
        "        # Return the list of hash codes\n",
        "        return hashed_data"
      ],
      "metadata": {
        "id": "mf2XpJLEtdkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_buckets = 2**12\n",
        "projection_dim = 128\n",
        "\n",
        "# Initialize LSH\n",
        "lsh = LSH(num_buckets, projection_dim)"
      ],
      "metadata": {
        "id": "hK56fa0xuyHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hash the representation vectors\n",
        "hashed_representations = lsh.hash_dataset(representation_vectors_np)"
      ],
      "metadata": {
        "id": "1FfVrzVQvJWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the resulting hash codes\n",
        "print(\"Hash Codes:\")\n",
        "for i, hash_code in enumerate(hashed_representations):\n",
        "    print(f\"Vector {i + 1}: {hash_code}\")"
      ],
      "metadata": {
        "id": "MkSJxHkVvKwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define data transformations\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download MNIST dataset\n",
        "mnist_train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "mnist_test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Download Fashion MNIST dataset\n",
        "fmnist_train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "fmnist_test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "LzscySL7vPmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "mnist_train_loader = torch.utils.data.DataLoader(mnist_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "mnist_test_loader = torch.utils.data.DataLoader(mnist_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "fmnist_train_loader = torch.utils.data.DataLoader(fmnist_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "fmnist_test_loader = torch.utils.data.DataLoader(fmnist_test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "MB7-nWztvYmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate query data\n",
        "mnist_queries = [mnist_test_dataset[i][0] for i in range(10000)]\n",
        "fashion_mnist_queries = [fmnist_test_dataset[i][0] for i in range(10000)]\n",
        "\n",
        "mnist_queries2 = [mnist_test_dataset[i][0] for i in range(20000)]\n",
        "fashion_mnist_queries2 = [fmnist_test_dataset[i][0] for i in range(20000)]"
      ],
      "metadata": {
        "id": "meu-5hqmvcQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain representations\n",
        "def get_representation(model, query_data):\n",
        "    device = next(model.parameters()).device  # Get the device of the model parameters\n",
        "    query_data = query_data.to(device)  # Move input data to the same device as the model\n",
        "    with torch.no_grad():\n",
        "        representation = model.encoder(query_data)\n",
        "    return representation\n",
        "\n",
        "\n",
        "mnist_representations = get_representation(simclr_model, torch.stack(mnist_queries))\n",
        "fashion_mnist_representations = get_representation(simclr_model, torch.stack(fashion_mnist_queries))"
      ],
      "metadata": {
        "id": "-VBZcMgevgHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lsh_estimation(representations, num_buckets=2**12):\n",
        "    # Step 1: Hash the representations\n",
        "    hash_values = np.array([hash_function(rep) for rep in representations])\n",
        "\n",
        "    # Step 2: Count unique buckets\n",
        "    unique_buckets = np.unique(hash_values)\n",
        "\n",
        "    # Step 3: Calculate fraction\n",
        "    fraction_occupied = len(unique_buckets) / num_buckets\n",
        "\n",
        "    return fraction_occupied\n",
        "\n",
        "def hash_function(vector):\n",
        "    return hash(tuple(vector.tolist()))"
      ],
      "metadata": {
        "id": "txccYO1TvsnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraction_10000 = lsh_estimation(mnist_representations[:10000])\n",
        "fashion_mnist_fraction = lsh_estimation(fashion_mnist_representations[:10000])\n",
        "\n",
        "fraction_20000 = lsh_estimation(mnist_representations[:20000])\n",
        "fashion_mnist_fraction2 = lsh_estimation(fashion_mnist_representations[:20000])\n",
        "\n",
        "print(f\"Fraction of embedding space occupied by MNIST: {fraction_10000}\")\n",
        "print(f\"Fraction of embedding space occupied by Fashion MNIST: {fashion_mnist_fraction}\")"
      ],
      "metadata": {
        "id": "bEUKPo_Bvwfg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}